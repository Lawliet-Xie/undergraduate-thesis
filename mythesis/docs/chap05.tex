\chapter{总结与展望}

\label{cha:conclusion}

本文提出了一个新的UDA框架用于跨模态医学图像分割。该框架利用解耦表示学习来提取多模态图像的解剖学特征和模态特征，同时利用对抗学习来进行图像自适应和特征自适应的融合。我们在不成对的多模态心脏数据集MMWHS上验证了该方法的效果。实验结果表明该框架改进域位移问题的有效性。

对于未来的工作，可以把该框架从2D图像扩展到与临床诊断更相关的3D图像，同时应用到不同的多模态数据集上来验证方法的鲁棒性以及泛化性，此外，可以利用生成对抗网络来进行多模态医学图像的生成进行自监督训练来缓解缺乏带标注医学图像数据的问题。
